File:ws.......
train with 10 epochs and 8 batch size
Epoch 1/10

Epoch 00001: val_loss improved from inf to 0.12932, saving model to model/ws_model_weight.h5
8453/8453 - 44s - loss: 0.1638 - acc: 0.9356 - val_loss: 0.1293 - val_acc: 0.9514 - lr: 0.0010
Epoch 2/10

Epoch 00002: val_loss improved from 0.12932 to 0.11228, saving model to model/ws_model_weight.h5
8453/8453 - 44s - loss: 0.1192 - acc: 0.9546 - val_loss: 0.1123 - val_acc: 0.9595 - lr: 0.0010
Epoch 3/10

Epoch 00003: val_loss did not improve from 0.11228
8453/8453 - 44s - loss: 0.0997 - acc: 0.9622 - val_loss: 0.1177 - val_acc: 0.9561 - lr: 0.0010
Epoch 4/10

Epoch 00004: val_loss did not improve from 0.11228
8453/8453 - 44s - loss: 0.0834 - acc: 0.9679 - val_loss: 0.1145 - val_acc: 0.9587 - lr: 0.0010
Epoch 5/10

Epoch 00005: val_loss did not improve from 0.11228
8453/8453 - 44s - loss: 0.0675 - acc: 0.9743 - val_loss: 0.1176 - val_acc: 0.9586 - lr: 0.0010
Epoch 6/10

Epoch 00006: val_loss did not improve from 0.11228
8453/8453 - 44s - loss: 0.0570 - acc: 0.9784 - val_loss: 0.1323 - val_acc: 0.9591 - lr: 0.0010
Epoch 7/10

Epoch 00007: val_loss did not improve from 0.11228
8453/8453 - 43s - loss: 0.0477 - acc: 0.9816 - val_loss: 0.1279 - val_acc: 0.9575 - lr: 0.0010
Epoch 8/10

Epoch 00008: val_loss did not improve from 0.11228
8453/8453 - 44s - loss: 0.0406 - acc: 0.9850 - val_loss: 0.1506 - val_acc: 0.9583 - lr: 0.0010
Epoch 9/10

Epoch 00009: val_loss did not improve from 0.11228
8453/8453 - 43s - loss: 0.0354 - acc: 0.9869 - val_loss: 0.1566 - val_acc: 0.9611 - lr: 0.0010
Epoch 10/10

Epoch 00010: val_loss did not improve from 0.11228
8453/8453 - 43s - loss: 0.0317 - acc: 0.9884 - val_loss: 0.1685 - val_acc: 0.9569 - lr: 0.0010
train with 10 epochs and 16 batch size
Epoch 1/10

Epoch 00001: val_loss did not improve from 0.11228
4227/4227 - 28s - loss: 0.0205 - acc: 0.9927 - val_loss: 0.1763 - val_acc: 0.9631 - lr: 0.0010
Epoch 2/10

Epoch 00002: val_loss did not improve from 0.11228
4227/4227 - 28s - loss: 0.0170 - acc: 0.9937 - val_loss: 0.1996 - val_acc: 0.9622 - lr: 0.0010
Epoch 3/10

Epoch 00003: val_loss did not improve from 0.11228
4227/4227 - 28s - loss: 0.0179 - acc: 0.9936 - val_loss: 0.1958 - val_acc: 0.9621 - lr: 0.0010
Epoch 4/10

Epoch 00004: val_loss did not improve from 0.11228
4227/4227 - 28s - loss: 0.0161 - acc: 0.9945 - val_loss: 0.2116 - val_acc: 0.9615 - lr: 0.0010
Epoch 5/10

Epoch 00005: val_loss did not improve from 0.11228
4227/4227 - 28s - loss: 0.0145 - acc: 0.9949 - val_loss: 0.2002 - val_acc: 0.9625 - lr: 0.0010
Epoch 6/10

Epoch 00006: val_loss did not improve from 0.11228
4227/4227 - 27s - loss: 0.0139 - acc: 0.9948 - val_loss: 0.2343 - val_acc: 0.9609 - lr: 0.0010
Epoch 7/10

Epoch 00007: val_loss did not improve from 0.11228
4227/4227 - 27s - loss: 0.0131 - acc: 0.9954 - val_loss: 0.2126 - val_acc: 0.9607 - lr: 0.0010
Epoch 8/10

Epoch 00008: val_loss did not improve from 0.11228
4227/4227 - 28s - loss: 0.0137 - acc: 0.9951 - val_loss: 0.2213 - val_acc: 0.9631 - lr: 0.0010
Epoch 9/10

Epoch 00009: val_loss did not improve from 0.11228
4227/4227 - 28s - loss: 0.0121 - acc: 0.9954 - val_loss: 0.2385 - val_acc: 0.9591 - lr: 0.0010
Epoch 10/10

Epoch 00010: val_loss did not improve from 0.11228
4227/4227 - 28s - loss: 0.0113 - acc: 0.9960 - val_loss: 0.2236 - val_acc: 0.9626 - lr: 0.0010
train with 10 epochs and 32 batch size
Epoch 1/10

Epoch 00001: val_loss did not improve from 0.11228
2114/2114 - 20s - loss: 0.0080 - acc: 0.9969 - val_loss: 0.2315 - val_acc: 0.9617 - lr: 0.0010
Epoch 2/10

Epoch 00002: val_loss did not improve from 0.11228
2114/2114 - 20s - loss: 0.0067 - acc: 0.9977 - val_loss: 0.2323 - val_acc: 0.9637 - lr: 0.0010
Epoch 3/10

Epoch 00003: val_loss did not improve from 0.11228
2114/2114 - 20s - loss: 0.0070 - acc: 0.9977 - val_loss: 0.2509 - val_acc: 0.9646 - lr: 0.0010
Epoch 4/10

Epoch 00004: val_loss did not improve from 0.11228
2114/2114 - 20s - loss: 0.0065 - acc: 0.9977 - val_loss: 0.2587 - val_acc: 0.9611 - lr: 0.0010
Epoch 5/10

Epoch 00005: val_loss did not improve from 0.11228
2114/2114 - 20s - loss: 0.0068 - acc: 0.9976 - val_loss: 0.2441 - val_acc: 0.9634 - lr: 0.0010
Epoch 6/10

Epoch 00006: val_loss did not improve from 0.11228
2114/2114 - 20s - loss: 0.0065 - acc: 0.9978 - val_loss: 0.2564 - val_acc: 0.9618 - lr: 0.0010
Epoch 7/10

Epoch 00007: val_loss did not improve from 0.11228
2114/2114 - 20s - loss: 0.0068 - acc: 0.9975 - val_loss: 0.2507 - val_acc: 0.9630 - lr: 0.0010
Epoch 8/10

Epoch 00008: val_loss did not improve from 0.11228
2114/2114 - 20s - loss: 0.0061 - acc: 0.9976 - val_loss: 0.2760 - val_acc: 0.9637 - lr: 0.0010
Epoch 9/10

Epoch 00009: val_loss did not improve from 0.11228
2114/2114 - 20s - loss: 0.0067 - acc: 0.9977 - val_loss: 0.2666 - val_acc: 0.9637 - lr: 0.0010
Epoch 10/10

Epoch 00010: val_loss did not improve from 0.11228
2114/2114 - 20s - loss: 0.0055 - acc: 0.9980 - val_loss: 0.2771 - val_acc: 0.9613 - lr: 0.0010
train with 10 epochs and 64 batch size
Epoch 1/10

Epoch 00001: val_loss did not improve from 0.11228
1057/1057 - 15s - loss: 0.0042 - acc: 0.9986 - val_loss: 0.2788 - val_acc: 0.9635 - lr: 0.0010
Epoch 2/10

Epoch 00002: val_loss did not improve from 0.11228
1057/1057 - 15s - loss: 0.0040 - acc: 0.9985 - val_loss: 0.2762 - val_acc: 0.9626 - lr: 0.0010
Epoch 3/10

Epoch 00003: val_loss did not improve from 0.11228
1057/1057 - 15s - loss: 0.0040 - acc: 0.9985 - val_loss: 0.2927 - val_acc: 0.9638 - lr: 0.0010
Epoch 4/10

Epoch 00004: val_loss did not improve from 0.11228
1057/1057 - 15s - loss: 0.0037 - acc: 0.9987 - val_loss: 0.2813 - val_acc: 0.9619 - lr: 0.0010
Epoch 5/10

Epoch 00005: val_loss did not improve from 0.11228
1057/1057 - 15s - loss: 0.0037 - acc: 0.9986 - val_loss: 0.2992 - val_acc: 0.9615 - lr: 0.0010
Epoch 6/10

Epoch 00006: val_loss did not improve from 0.11228
1057/1057 - 15s - loss: 0.0040 - acc: 0.9986 - val_loss: 0.2898 - val_acc: 0.9597 - lr: 0.0010
Epoch 7/10

Epoch 00007: val_loss did not improve from 0.11228
1057/1057 - 15s - loss: 0.0047 - acc: 0.9983 - val_loss: 0.2773 - val_acc: 0.9623 - lr: 0.0010
Epoch 8/10

Epoch 00008: val_loss did not improve from 0.11228
1057/1057 - 15s - loss: 0.0033 - acc: 0.9988 - val_loss: 0.2993 - val_acc: 0.9647 - lr: 0.0010
Epoch 9/10

Epoch 00009: val_loss did not improve from 0.11228
1057/1057 - 15s - loss: 0.0040 - acc: 0.9986 - val_loss: 0.2931 - val_acc: 0.9639 - lr: 0.0010
Epoch 10/10

Epoch 00010: val_loss did not improve from 0.11228
1057/1057 - 15s - loss: 0.0032 - acc: 0.9988 - val_loss: 0.3018 - val_acc: 0.9622 - lr: 0.0010
train with 10 epochs and 128 batch size
Epoch 1/10

Epoch 00001: val_loss did not improve from 0.11228
529/529 - 12s - loss: 0.0027 - acc: 0.9990 - val_loss: 0.3076 - val_acc: 0.9630 - lr: 0.0010
Epoch 2/10

Epoch 00002: val_loss did not improve from 0.11228
529/529 - 12s - loss: 0.0023 - acc: 0.9992 - val_loss: 0.3256 - val_acc: 0.9625 - lr: 0.0010
Epoch 3/10

Epoch 00003: val_loss did not improve from 0.11228
529/529 - 13s - loss: 0.0020 - acc: 0.9993 - val_loss: 0.3196 - val_acc: 0.9626 - lr: 0.0010
Epoch 4/10

Epoch 00004: val_loss did not improve from 0.11228
529/529 - 12s - loss: 0.0025 - acc: 0.9990 - val_loss: 0.3207 - val_acc: 0.9639 - lr: 0.0010
Epoch 5/10

Epoch 00005: val_loss did not improve from 0.11228
529/529 - 12s - loss: 0.0019 - acc: 0.9993 - val_loss: 0.3340 - val_acc: 0.9638 - lr: 0.0010
Epoch 6/10

Epoch 00006: val_loss did not improve from 0.11228
529/529 - 13s - loss: 0.0019 - acc: 0.9992 - val_loss: 0.3353 - val_acc: 0.9622 - lr: 0.0010
Epoch 7/10

Epoch 00007: val_loss did not improve from 0.11228
529/529 - 13s - loss: 0.0024 - acc: 0.9990 - val_loss: 0.3149 - val_acc: 0.9629 - lr: 0.0010
Epoch 8/10

Epoch 00008: val_loss did not improve from 0.11228
529/529 - 13s - loss: 0.0019 - acc: 0.9992 - val_loss: 0.3332 - val_acc: 0.9634 - lr: 0.0010
Epoch 9/10

Epoch 00009: val_loss did not improve from 0.11228
529/529 - 13s - loss: 0.0022 - acc: 0.9991 - val_loss: 0.3287 - val_acc: 0.9633 - lr: 0.0010
Epoch 10/10

Epoch 00010: val_loss did not improve from 0.11228
529/529 - 13s - loss: 0.0029 - acc: 0.9991 - val_loss: 0.3296 - val_acc: 0.9622 - lr: 0.0010
train with 5 epochs and 256 batch size
Epoch 1/5

Epoch 00001: val_loss did not improve from 0.11228
265/265 - 11s - loss: 0.0019 - acc: 0.9992 - val_loss: 0.3351 - val_acc: 0.9623 - lr: 0.0010
Epoch 2/5

Epoch 00002: val_loss did not improve from 0.11228
265/265 - 11s - loss: 0.0022 - acc: 0.9992 - val_loss: 0.3373 - val_acc: 0.9626 - lr: 0.0010
Epoch 3/5

Epoch 00003: val_loss did not improve from 0.11228
265/265 - 11s - loss: 0.0017 - acc: 0.9992 - val_loss: 0.3399 - val_acc: 0.9615 - lr: 0.0010
Epoch 4/5

Epoch 00004: val_loss did not improve from 0.11228
265/265 - 11s - loss: 0.0014 - acc: 0.9993 - val_loss: 0.3423 - val_acc: 0.9629 - lr: 0.0010
Epoch 5/5

Epoch 00005: val_loss did not improve from 0.11228
265/265 - 11s - loss: 0.0015 - acc: 0.9993 - val_loss: 0.3406 - val_acc: 0.9623 - lr: 0.0010
train with 5 epochs and 512 batch size
Epoch 1/5

Epoch 00001: val_loss did not improve from 0.11228
133/133 - 10s - loss: 0.0019 - acc: 0.9993 - val_loss: 0.3393 - val_acc: 0.9630 - lr: 0.0010
Epoch 2/5

Epoch 00002: val_loss did not improve from 0.11228
133/133 - 10s - loss: 0.0016 - acc: 0.9994 - val_loss: 0.3449 - val_acc: 0.9639 - lr: 0.0010
Epoch 3/5

Epoch 00003: val_loss did not improve from 0.11228
133/133 - 10s - loss: 0.0014 - acc: 0.9994 - val_loss: 0.3517 - val_acc: 0.9634 - lr: 0.0010
Epoch 4/5

Epoch 00004: val_loss did not improve from 0.11228
133/133 - 9s - loss: 0.0014 - acc: 0.9994 - val_loss: 0.3492 - val_acc: 0.9625 - lr: 0.0010
Epoch 5/5

Epoch 00005: val_loss did not improve from 0.11228
133/133 - 9s - loss: 0.0010 - acc: 0.9996 - val_loss: 0.3509 - val_acc: 0.9623 - lr: 0.0010
